
@article{tang_digital_2018,
	title = {Digital {Signal} {Modulation} {Classification} {With} {Data} {Augmentation} {Using} {Generative} {Adversarial} {Nets} in {Cognitive} {Radio} {Networks}},
	volume = {6},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2018.2815741},
	abstract = {Automated modulation classification plays a very important part in cognitive radio networks. Deep learning is also a powerful tool that we could not overlook its potential in addressing signal modulation recognition problem. In our last work, we propose a new data conversion algorithm in order to gain a better classification accuracy of communication signal modulation, but we still believe that the convolution neural network (CNN) can work better. However, its application to signal modulation recognition is often hampered by insufficient data and overfitting. Here, we propose a smart approach to programmatic data augmentation method by using the auxiliary classifier generative adversarial networks (ACGANs). The famous CNN model, AlexNet, has been utilized to be the classifier and ACGAN to be the generator, which will enlarge our data set. In order to alleviate the common issues in the traditional generative adversarial nets training, such as discriminator overfitting, generator disconverge, and mode collapse, we apply several training tricks in our training. With the result on original data set as our baseline, we will evaluate our result on enlarged data set to validate the ACGAN’s performance. The result shows that we can gain 0.1 6\% increase in the classification accuracy in the ACGAN-based data set.},
	journal = {IEEE Access},
	author = {Tang, Bin and Tu, Ya and Zhang, Zhaoyue and Lin, Yun},
	year = {2018},
	keywords = {classification algorithms, Cognitive radio, Constellation diagram, convolutional networks, deep learning, Gallium nitride, generative adversarial net, Image color analysis, modulation recognition, pattern recognition, Phase shift keying, Signal to noise ratio, Training},
	pages = {15713--15722},
	file = {IEEE Xplore Abstract Record:/Users/rubenrosales/Zotero/storage/MFQDCCID/Tang et al. - 2018 - Digital Signal Modulation Classification With Data.html:text/html;IEEE Xplore Full Text PDF:/Users/rubenrosales/Zotero/storage/W9NG2XU8/Tang et al. - 2018 - Digital Signal Modulation Classification With Data.pdf:application/pdf}
}

@misc{noauthor_fig_nodate,
	title = {Fig (3-1): {Different} {Wavelet} families {The} first letters has a relation...},
	shorttitle = {Fig (3-1)},
	url = {https://www.researchgate.net/figure/Fig-3-1-Different-Wavelet-families-The-first-letters-has-a-relation-to-the-wavelet_fig2_323005213},
	abstract = {Download scientific diagram {\textbar} Different Wavelet families The first letters has a relation to the wavelet transform is Haar wavelet. It was presented by the mathematician Alfrd Haar in 1909. However, the idea of the wavelet did not present at that time. Until 1981, the model of wavelet was proposed by Jean Morlet. Later, Morlet and Alex Grossman invented the term wavelet in 1984. Before 1985, Haar wavelet was just orthogonal wavelet. A lot of studies although that there was no orthogonal wavelet excepted Haar wavelet. Likely, mathematician called Yves Meyer presented the 2nd orthogonal wavelet called Meyer wavelet in 1985. More than those scholars joined this field in the 1st international conference was held in France in 1987. In 1988, Stephane Mallat and Meyer presented the notation of multi resolution. In the same year, Daubechies found a systematical method to design the orthogonal  from publication: Time-Frequency analysis of Different types of signals {\textbar} Cardiovascular disorders (CVD’s) or Heart disease, which is called coronary artery disease, is a broad term that can refer to a human heart condition. CVD’s are the first cause of death internationally. Taking in consideration that heart auscultation still the primary tool... {\textbar} Heart Sounds, Time-Frequency Analysis and Heart Diseases {\textbar} ResearchGate, the professional network for scientists.},
	language = {en},
	urldate = {2020-03-13},
	journal = {ResearchGate},
	note = {Library Catalog: www.researchgate.net},
	file = {Snapshot:/Users/rubenrosales/Zotero/storage/FC5ZBWSF/Fig-3-1-Different-Wavelet-families-The-first-letters-has-a-relation-to-the-wavelet_fig2_3230052.html:text/html}
}

@article{mesleh_spatial_2008,
	title = {Spatial {Modulation}},
	volume = {57},
	issn = {1939-9359},
	doi = {10.1109/TVT.2007.912136},
	abstract = {Spatial modulation (SM) is a recently developed transmission technique that uses multiple antennas. The basic idea is to map a block of information bits to two information carrying units: 1) a symbol that was chosen from a constellation diagram and 2) a unique transmit antenna number that was chosen from a set of transmit antennas. The use of the transmit antenna number as an information-bearing unit increases the overall spectral efficiency by the base-two logarithm of the number of transmit antennas. At the receiver, a maximum receive ratio combining algorithm is used to retrieve the transmitted block of information bits. Here, we apply SM to orthogonal frequency division multiplexing (OFDM) transmission. We develop an analytical approach for symbol error ratio (SER) analysis of the SM algorithm in independent identically distributed (i.i.d.) Rayleigh channels. The analytical and simulation results closely match. The performance and the receiver complexity of the SM-OFDM technique are compared to those of the vertical Bell Labs layered space-time (V-BLAST-OFDM) and Alamouti-OFDM algorithms. V-BLAST uses minimum mean square error (MMSE) detection with ordered successive interference cancellation. The combined effect of spatial correlation, mutual antenna coupling, and Rician fading on both coded and uncoded systems are presented. It is shown that, for the same spectral efficiency, SM results in a reduction of around 90\% in receiver complexity as compared to V-BLAST and nearly the same receiver complexity as Alamouti. In addition, we show that SM achieves better performance in all studied channel conditions, as compared with other techniques. It is also shown to efficiently work for any configuration of transmit and receive antennas, even for the case of fewer receive antennas than transmit antennas.},
	number = {4},
	journal = {IEEE Transactions on Vehicular Technology},
	author = {Mesleh, Raed Y. and Haas, Harald and Sinanovic, Sinan and Ahn, Chang Wook and Yun, Sangboh},
	month = jul,
	year = {2008},
	note = {Conference Name: IEEE Transactions on Vehicular Technology},
	keywords = {Constellation diagram, Algorithm design and analysis, Analytical models, Error analysis, ICI, information bearing unit, information bits, information carrying unit, Information retrieval, Interchannel interference (ICI), interference cancellation, maximum receive ratio combining algorithm, MIMO, MMSE, modulation, MRRC, multiple antennas, multiple-input–multiple-output (MIMO), Mutual Antenna Coupling, OFDM, orthogonal frequency division multiplexing (OFDM), orthogonal frequency division multiplexing transmission, Rayleigh channels, receive antenna, receiver complexity, Receiver Complexity, receivers, receiving antennas, Receiving antennas, Rician Fading, Samarium, space–time coding (STC) coded modulation, Spatial Correlation, spatial modulation, Spatial Modulation, spatial modulation (SM), spectral efficiency, STBC, symbol error ratio analysis, transmission technique, transmit antenna number, transmitting antennas, Transmitting antennas, V-BLAST, vertical Bell Labs layered space–time (V-BLAST)},
	pages = {2228--2241},
	file = {IEEE Xplore Abstract Record:/Users/rubenrosales/Zotero/storage/ZU2BQLHQ/4382913.html:text/html}
}

@article{wang_multilevel_2018,
	title = {Multilevel {Wavelet} {Decomposition} {Network} for {Interpretable} {Time} {Series} {Analysis}},
	url = {http://arxiv.org/abs/1806.08946},
	abstract = {Recent years have witnessed the unprecedented rising of time series from almost all kindes of academic and industrial fields. Various types of deep neural network models have been introduced to time series analysis, but the important frequency information is yet lack of effective modeling. In light of this, in this paper we propose a wavelet-based neural network structure called multilevel Wavelet Decomposition Network (mWDN) for building frequency-aware deep learning models for time series analysis. mWDN preserves the advantage of multilevel discrete wavelet decomposition in frequency learning while enables the fine-tuning of all parameters under a deep neural network framework. Based on mWDN, we further propose two deep learning models called Residual Classification Flow (RCF) and multi-frequecy Long Short-Term Memory (mLSTM) for time series classification and forecasting, respectively. The two models take all or partial mWDN decomposed sub-series in different frequencies as input, and resort to the back propagation algorithm to learn all the parameters globally, which enables seamless embedding of wavelet-based frequency analysis into deep learning frameworks. Extensive experiments on 40 UCR datasets and a real-world user volume dataset demonstrate the excellent performance of our time series models based on mWDN. In particular, we propose an importance analysis method to mWDN based models, which successfully identifies those time-series elements and mWDN layers that are crucially important to time series analysis. This indeed indicates the interpretability advantage of mWDN, and can be viewed as an indepth exploration to interpretable deep learning.},
	urldate = {2020-03-14},
	journal = {arXiv:1806.08946 [cs, eess, stat]},
	author = {Wang, Jingyuan and Wang, Ze and Li, Jianfeng and Wu, Junjie},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.08946},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
	file = {arXiv Fulltext PDF:/Users/rubenrosales/Zotero/storage/C7TA364N/Wang et al. - 2018 - Multilevel Wavelet Decomposition Network for Inter.pdf:application/pdf;arXiv.org Snapshot:/Users/rubenrosales/Zotero/storage/8YWAXTXA/1806.html:text/html}
}

@article{wang_hybrid_2019,
	title = {Hybrid {Predictive} {Model}: {When} an {Interpretable} {Model} {Collaborates} with a {Black}-box {Model}},
	shorttitle = {Hybrid {Predictive} {Model}},
	url = {http://arxiv.org/abs/1905.04241},
	abstract = {Interpretable machine learning has become a strong competitor for traditional black-box models. However, the possible loss of the predictive performance for gaining interpretability is often inevitable, putting practitioners in a dilemma of choosing between high accuracy (black-box models) and interpretability (interpretable models). In this work, we propose a novel framework for building a Hybrid Predictive Model (HPM) that integrates an interpretable model with any black-box model to combine their strengths. The interpretable model substitutes the black-box model on a subset of data where the black-box is overkill or nearly overkill, gaining transparency at no or low cost of the predictive accuracy. We design a principled objective function that considers predictive accuracy, model interpretability, and model transparency (defined as the percentage of data processed by the interpretable substitute.) Under this framework, we propose two hybrid models, one substituting with association rules and the other with linear models, and we design customized training algorithms for both models. We test the hybrid models on structured data and text data where interpretable models collaborate with various state-of-the-art black-box models. Results show that hybrid models obtain an efficient trade-off between transparency and predictive performance, characterized by our proposed efficient frontiers.},
	urldate = {2020-03-14},
	journal = {arXiv:1905.04241 [cs, stat]},
	author = {Wang, Tong and Lin, Qihang},
	month = may,
	year = {2019},
	note = {arXiv: 1905.04241},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/rubenrosales/Zotero/storage/TT5WKYX4/Wang and Lin - 2019 - Hybrid Predictive Model When an Interpretable Mod.pdf:application/pdf;arXiv.org Snapshot:/Users/rubenrosales/Zotero/storage/IAE9MKM5/1905.html:text/html}
}

@article{oshea_convolutional_2016,
	title = {Convolutional {Radio} {Modulation} {Recognition} {Networks}},
	url = {http://arxiv.org/abs/1602.04105},
	abstract = {We study the adaptation of convolutional neural networks to the complex temporal radio signal domain. We compare the efficacy of radio modulation classification using naively learned features against using expert features which are widely used in the field today and we show significant performance improvements. We show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task especially at low signal to noise ratio.},
	urldate = {2020-03-14},
	journal = {arXiv:1602.04105 [cs]},
	author = {O'Shea, Timothy J. and Corgan, Johnathan and Clancy, T. Charles},
	month = jun,
	year = {2016},
	note = {arXiv: 1602.04105},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/rubenrosales/Zotero/storage/C6E8NQZU/O'Shea et al. - 2016 - Convolutional Radio Modulation Recognition Network.pdf:application/pdf;arXiv.org Snapshot:/Users/rubenrosales/Zotero/storage/LND3XTWF/1602.html:text/html}
}

@book{strang_wavelets_1996,
	title = {Wavelets and {Filter} {Banks}},
	isbn = {978-0-9614088-7-9},
	url = {https://books.google.com/books?id=Z76N_Ab5pp8C},
	publisher = {Wellesley-Cambridge Press},
	author = {Strang, G. and Nguyen, T.},
	year = {1996},
	lccn = {96028791}
}

@article{hill_uncertainty_nodate,
	title = {{THE} {UNCERTAINTY} {PRINCIPLE} {FOR} {FOURIER} {TRANSFORMS} {ON} {THE} {REAL} {LINE}},
	abstract = {This paper will explore the heuristic principle that a function on the line and its Fourier transform cannot both be concentrated on small sets. We begin with the basic properties of the Fourier transform and show that a function and its Fourier transform cannot both have compact support. From there we prove the Fourier inversion theorem and use this to prove the classical uncertainty principle which shows that the spread of a function and its Fourier transform are inversely proportional. Finally, we extend our compactness result from earlier and show that a function and its Fourier transform cannot both be supported on ﬁnite sets.},
	language = {en},
	author = {Hill, Mitch},
	pages = {17},
	file = {Hill - THE UNCERTAINTY PRINCIPLE FOR FOURIER TRANSFORMS O.pdf:/Users/rubenrosales/Zotero/storage/E7I625TQ/Hill - THE UNCERTAINTY PRINCIPLE FOR FOURIER TRANSFORMS O.pdf:application/pdf}
}

@inproceedings{kim_multimodal_2018,
	address = {Galway, Ireland},
	series = {{ASSETS} '18},
	title = {Multimodal {Deep} {Learning} using {Images} and {Text} for {Information} {Graphic} {Classification}},
	isbn = {978-1-4503-5650-3},
	url = {https://doi.org/10.1145/3234695.3236357},
	doi = {10.1145/3234695.3236357},
	abstract = {Information graphics, e.g. line or bar graphs, are often displayed in documents and popular media to support an intended message, but for a growing number of people, they are missing the point. The World Health Organization estimates that the number of people with vision impairment could triple in the next thirty years due to population growth and aging. If a graphic is not described, explained in the text, or missing alt tags and other metadata (as is often the case in popular media), the intended message is lost or not adequately conveyed. In this work, we describe a multimodal deep learning approach that supports the communication of the intended message. The multimodal model uses both the pixel data and text data in a single neural network to classify the information graphic into an intention category that has previously been validated as useful for people who are blind or who are visually impaired. Furthermore, we collect a new dataset of information graphics and present qualitative and quantitative results that show our multimodal model exceeds the performance of any one modality alone, and even surpasses the capabilities of the average human annotator.},
	urldate = {2020-03-13},
	booktitle = {Proceedings of the 20th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Edward and McCoy, Kathleen F.},
	month = oct,
	year = {2018},
	keywords = {deep learning, assistive technology, classification, information graphic, multimodal machine learning},
	pages = {143--148}
}

@article{wang_encoding_nodate,
	title = {Encoding {Time} {Series} as {Images} for {Visual} {Inspection} and {Classification} {Using} {Tiled} {Convolutional} {Neural} {Networks}},
	abstract = {Inspired by recent successes of deep learning in computer vision and speech recognition, we propose a novel framework to encode time series data as different types of images, namely, Gramian Angular Fields (GAF) and Markov Transition Fields (MTF). This enables the use of techniques from computer vision for classiﬁcation. Using a polar coordinate system, GAF images are represented as a Gramian matrix where each element is the trigonometric sum (i.e., superposition of directions) between different time intervals. MTF images represent the ﬁrst order Markov transition probability along one dimension and temporal dependency along the other. We used Tiled Convolutional Neural Networks (tiled CNNs) on 12 standard datasets to learn high-level features from individual GAF, MTF, and GAF-MTF images that resulted from combining GAF and MTF representations into a single image. The classiﬁcation results of our approach are competitive with ﬁve stateof-the-art approaches. An analysis of the features and weights learned via tiled CNNs explains why the approach works.},
	language = {en},
	author = {Wang, Zhiguang and Oates, Tim},
	pages = {7},
	file = {Wang and Oates - Encoding Time Series as Images for Visual Inspecti.pdf:/Users/rubenrosales/Zotero/storage/L5TTWCZT/Wang and Oates - Encoding Time Series as Images for Visual Inspecti.pdf:application/pdf}
}

@article{donahue_long-term_2016,
	title = {Long-term {Recurrent} {Convolutional} {Networks} for {Visual} {Recognition} and {Description}},
	url = {http://arxiv.org/abs/1411.4389},
	abstract = {Models based on deep convolutional networks have dominated recent image interpretation tasks; we investigate whether models which are also recurrent, or "temporally deep", are effective for tasks involving sequences, visual and otherwise. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image description and retrieval problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are "doubly deep"' in that they can be compositional in spatial and temporal "layers". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable-length inputs (e.g., video frames) to variable length outputs (e.g., natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to modern visual convnet models and can be jointly trained to simultaneously learn temporal dynamics and convolutional perceptual representations. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.},
	urldate = {2020-03-16},
	journal = {arXiv:1411.4389 [cs]},
	author = {Donahue, Jeff and Hendricks, Lisa Anne and Rohrbach, Marcus and Venugopalan, Subhashini and Guadarrama, Sergio and Saenko, Kate and Darrell, Trevor},
	month = may,
	year = {2016},
	note = {arXiv: 1411.4389},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Originally presented at CVPR 2015 (oral). Updated version (accepted as a TPAMI journal article) includes additional results},
	file = {arXiv Fulltext PDF:/Users/rubenrosales/Zotero/storage/B8RT9GF3/Donahue et al. - 2016 - Long-term Recurrent Convolutional Networks for Vis.pdf:application/pdf;arXiv.org Snapshot:/Users/rubenrosales/Zotero/storage/2HBMJRGD/1411.html:text/html}
}

@article{aqib_smarter_2019,
	title = {Smarter {Traffic} {Prediction} {Using} {Big} {Data}, {In}-{Memory} {Computing}, {Deep} {Learning} and {GPUs}},
	volume = {19},
	doi = {10.3390/s19092206},
	abstract = {Road transportation is the backbone of modern economies, albeit it annually costs 1.25 million deaths and trillions of dollars to the global economy, and damages public health and the environment. Deep learning is among the leading-edge methods used for transportation-related predictions, however, the existing works are in their infancy, and fall short in multiple respects, including the use of datasets with limited sizes and scopes, and insufficient depth of the deep learning studies. This paper provides a novel and comprehensive approach toward large-scale, faster, and real-time traffic prediction by bringing four complementary cutting-edge technologies together: big data, deep learning, in-memory computing, and Graphics Processing Units (GPUs). We trained deep networks using over 11 years of data provided by the California Department of Transportation (Caltrans), the largest dataset that has been used in deep learning studies. Several combinations of the input attributes of the data along with various network configurations of the deep learning models were investigated for training and prediction purposes. The use of the pre-trained model for real-time prediction was explored. The paper contributes novel deep learning models, algorithms, implementation, analytics methodology, and software tool for smart cities, big data, high performance computing, and their convergence.},
	journal = {Sensors},
	author = {Aqib, Muhammad and Mehmood, Rashid and Alzahrani, Ahmed and Katib, Iyad and Albeshri, Aiiad and Altowaijri, Saleh},
	month = may,
	year = {2019},
	pages = {2206},
	file = {Full Text:/Users/rubenrosales/Zotero/storage/T327P3CG/Aqib et al. - 2019 - Smarter Traffic Prediction Using Big Data, In-Memo.pdf:application/pdf}
}

@article{yamashita_convolutional_2018,
	title = {Convolutional neural networks: an overview and application in radiology},
	volume = {9},
	copyright = {2018 The Author(s)},
	issn = {1869-4101},
	shorttitle = {Convolutional neural networks},
	url = {https://insightsimaging.springeropen.com/articles/10.1007/s13244-018-0639-9},
	doi = {10.1007/s13244-018-0639-9},
	abstract = {Convolutional neural network (CNN), a class of artificial neural networks that has become dominant in various computer vision tasks, is attracting interest across a variety of domains, including radiology. CNN is designed to automatically and adaptively learn spatial hierarchies of features through backpropagation by using multiple building blocks, such as convolution layers, pooling layers, and fully connected layers. This review article offers a perspective on the basic concepts of CNN and its application to various radiological tasks, and discusses its challenges and future directions in the field of radiology. Two challenges in applying CNN to radiological tasks, small dataset and overfitting, will also be covered in this article, as well as techniques to minimize them. Being familiar with the concepts and advantages, as well as limitations, of CNN is essential to leverage its potential in diagnostic radiology, with the goal of augmenting the performance of radiologists and improving patient care. • Convolutional neural network is a class of deep learning methods which has become dominant in various computer vision tasks and is attracting interest across a variety of domains, including radiology. • Convolutional neural network is composed of multiple building blocks, such as convolution layers, pooling layers, and fully connected layers, and is designed to automatically and adaptively learn spatial hierarchies of features through a backpropagation algorithm. • Familiarity with the concepts and advantages, as well as limitations, of convolutional neural network is essential to leverage its potential to improve radiologist performance and, eventually, patient care.},
	language = {en},
	number = {4},
	urldate = {2020-03-16},
	journal = {Insights into Imaging},
	author = {Yamashita, Rikiya and Nishio, Mizuho and Do, Richard Kinh Gian and Togashi, Kaori},
	month = aug,
	year = {2018},
	note = {Number: 4
Publisher: SpringerOpen},
	pages = {611--629},
	file = {Full Text PDF:/Users/rubenrosales/Zotero/storage/HPL2YGQI/Yamashita et al. - 2018 - Convolutional neural networks an overview and app.pdf:application/pdf;Snapshot:/Users/rubenrosales/Zotero/storage/MKSAYR4J/s13244-018-0639-9.html:text/html}
}

@article{liu_learn_2018,
	title = {Learn to {Combine} {Modalities} in {Multimodal} {Deep} {Learning}},
	url = {http://arxiv.org/abs/1805.11730},
	abstract = {Combining complementary information from multiple modalities is intuitively appealing for improving the performance of learning-based approaches. However, it is challenging to fully leverage different modalities due to practical challenges such as varying levels of noise and conflicts between modalities. Existing methods do not adopt a joint approach to capturing synergies between the modalities while simultaneously filtering noise and resolving conflicts on a per sample basis. In this work we propose a novel deep neural network based technique that multiplicatively combines information from different source modalities. Thus the model training process automatically focuses on information from more reliable modalities while reducing emphasis on the less reliable modalities. Furthermore, we propose an extension that multiplicatively combines not only the single-source modalities, but a set of mixtured source modalities to better capture cross-modal signal correlations. We demonstrate the effectiveness of our proposed technique by presenting empirical results on three multimodal classification tasks from different domains. The results show consistent accuracy improvements on all three tasks.},
	urldate = {2020-03-16},
	journal = {arXiv:1805.11730 [cs, stat]},
	author = {Liu, Kuan and Li, Yanen and Xu, Ning and Natarajan, Prem},
	month = may,
	year = {2018},
	note = {arXiv: 1805.11730},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/rubenrosales/Zotero/storage/QNPSJXTU/Liu et al. - 2018 - Learn to Combine Modalities in Multimodal Deep Lea.pdf:application/pdf;arXiv.org Snapshot:/Users/rubenrosales/Zotero/storage/8U7DHDE6/1805.html:text/html}
}

@article{alom_state---art_2019,
	title = {A {State}-of-the-{Art} {Survey} on {Deep} {Learning} {Theory} and {Architectures}},
	volume = {8},
	doi = {10.3390/electronics8030292},
	abstract = {In recent years, deep learning has garnered tremendous success in a variety of application domains. This new field of machine learning has been growing rapidly and has been applied to most traditional application domains, as well as some new areas that present more opportunities. Different methods have been proposed based on different categories of learning, including supervised, semi-supervised, and un-supervised learning. Experimental results show state-of-the-art performance using deep learning when compared to traditional machine learning approaches in the fields of image processing, computer vision, speech recognition, machine translation, art, medical imaging, medical information processing, robotics and control, bioinformatics, natural language processing, cybersecurity, and many others. This survey presents a brief survey on the advances that have occurred in the area of Deep Learning (DL), starting with the Deep Neural Network (DNN). The survey goes on to cover Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), including Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). Additionally, we have discussed recent developments, such as advanced variant DL techniques based on these DL approaches. This work considers most of the papers published after 2012 from when the history of deep learning began. Furthermore, DL approaches that have been explored and evaluated in different application domains are also included in this survey. We also included recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys that have been published on DL using neural networks and a survey on Reinforcement Learning (RL). However, those papers have not discussed individual advanced techniques for training large-scale deep learning models and the recently developed method of generative models.},
	journal = {Electronics},
	author = {Alom, Md. Zahangir and Taha, Tarek and Yakopcic, Chris and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst and Hasan, Mahmudul and Essen, Brian and Awwal, Abdul and Asari, Vijayan},
	month = mar,
	year = {2019},
	pages = {292},
	file = {Full Text:/Users/rubenrosales/Zotero/storage/9KJXP347/Alom et al. - 2019 - A State-of-the-Art Survey on Deep Learning Theory .pdf:application/pdf}
}

@article{lopez_development_2017,
	title = {Development of a {Computer} {Writing} {System} {Based} on {EOG}},
	volume = {17},
	doi = {10.3390/s17071505},
	abstract = {The development of a novel computer writing system based on eye movements is introduced herein. A system of these characteristics requires the consideration of three subsystems: (1) A hardware device for the acquisition and transmission of the signals generated by eye movement to the computer; (2) A software application that allows, among other functions, data processing in order to minimize noise and classify signals; and (3) A graphical interface that allows the user to write text easily on the computer screen using eye movements only. This work analyzes these three subsystems and proposes innovative and low cost solutions for each one of them. This computer writing system was tested with 20 users and its efficiency was compared to a traditional virtual keyboard. The results have shown an important reduction in the time spent on writing, which can be very useful, especially for people with severe motor disorders.},
	journal = {Sensors},
	author = {López, Alberto and Martin, Francisco Javier and Yangüela, David and Alvarez Peña, Constantina},
	month = jun,
	year = {2017},
	pages = {1505},
	file = {Full Text:/Users/rubenrosales/Zotero/storage/EBDJPPPI/López et al. - 2017 - Development of a Computer Writing System Based on .pdf:application/pdf}
}

@article{cui_multi-scale_2016,
	title = {Multi-{Scale} {Convolutional} {Neural} {Networks} for {Time} {Series} {Classification}},
	url = {http://arxiv.org/abs/1603.06995},
	abstract = {Time series classification (TSC), the problem of predicting class labels of time series, has been around for decades within the community of data mining and machine learning, and found many important applications such as biomedical engineering and clinical prediction. However, it still remains challenging and falls short of classification accuracy and efficiency. Traditional approaches typically involve extracting discriminative features from the original time series using dynamic time warping (DTW) or shapelet transformation, based on which an off-the-shelf classifier can be applied. These methods are ad-hoc and separate the feature extraction part with the classification part, which limits their accuracy performance. Plus, most existing methods fail to take into account the fact that time series often have features at different time scales. To address these problems, we propose a novel end-to-end neural network model, Multi-Scale Convolutional Neural Networks (MCNN), which incorporates feature extraction and classification in a single framework. Leveraging a novel multi-branch layer and learnable convolutional layers, MCNN automatically extracts features at different scales and frequencies, leading to superior feature representation. MCNN is also computationally efficient, as it naturally leverages GPU computing. We conduct comprehensive empirical evaluation with various existing methods on a large number of benchmark datasets, and show that MCNN advances the state-of-the-art by achieving superior accuracy performance than other leading methods.},
	urldate = {2020-03-16},
	journal = {arXiv:1603.06995 [cs]},
	author = {Cui, Zhicheng and Chen, Wenlin and Chen, Yixin},
	month = may,
	year = {2016},
	note = {arXiv: 1603.06995},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/rubenrosales/Zotero/storage/5GW2DA2K/Cui et al. - 2016 - Multi-Scale Convolutional Neural Networks for Time.pdf:application/pdf;arXiv.org Snapshot:/Users/rubenrosales/Zotero/storage/J7IHTBW2/1603.html:text/html}
}

@inproceedings{imani_curve_2016,
	title = {Curve fitting, filter bank and wavelet feature fusion for classification of {PCG} signals},
	doi = {10.1109/IranianCEE.2016.7585518},
	abstract = {The use of efficient feature extraction methods is very important to correctly classify the heart sound signal and to diagnosis the heart disease. In this paper, we propose two feature extraction algorithms for feature extraction of cardiac phonocardiography (PCG) signal. The both methods use the sequence discipline of PCG obtained by curve fitting model. In the first and the second methods, the sequence information is fused with features extracted by filter banks and by wavelets respectively. We used a dataset of PCG signals which contains the heart sounds of 98 persons (40 cases without heart disease and either no murmur or an innocent murmur and 58 cases with a variety of cardiac diagnoses and a pathologic systolic murmur). The experimental results show the efficiency of our proposed methods compared to some popular feature extraction methods from five different classification accuracy measures point of view.},
	booktitle = {2016 24th {Iranian} {Conference} on {Electrical} {Engineering} ({ICEE})},
	author = {Imani, Maryam and Ghassemian, Hassan},
	month = may,
	year = {2016},
	note = {ISSN: null},
	keywords = {classification, cardiac phonocardiography (PCG), cardiac phonocardiography signal, cardiology, curve fitting, Decision support systems, diseases, feature extraction, feature extraction method, filter bank, heart disease diagnosis, medical signal processing, patient diagnosis, PCG signal classification, phonocardiography, signal classification, wavelet feature fusion, wavelet transforms},
	pages = {203--208},
	file = {IEEE Xplore Abstract Record:/Users/rubenrosales/Zotero/storage/TTVA746X/7585518.html:text/html}
}

@article{wen_survey_2019,
	title = {A {Survey} on {Spatial} {Modulation} in {Emerging} {Wireless} {Systems}: {Research} {Progresses} and {Applications}},
	shorttitle = {A {Survey} on {Spatial} {Modulation} in {Emerging} {Wireless} {Systems}},
	url = {http://arxiv.org/abs/1907.02941},
	abstract = {Spatial modulation (SM) is an innovative and promising digital modulation technology that strikes an appealing trade-off between spectral efficiency and energy efficiency with a simple design philosophy. SM enjoys plenty of benefits and shows great potential to fulfill the requirements of future wireless communications. The key idea behind SM is to convey additional information typically through the ON/OFF states of transmit antennas and simultaneously save the implementation cost by reducing the number of radio frequency chains. As a result, the SM concept can have widespread effects on diverse applications and can be applied in other signal domains such as frequency/time/code/angle domain or even across multiple domains. This survey provides a comprehensive overview of the latest results and progresses in SM research. Specifically, the fundamental principles, variants of system design, and enhancements of SM are described in detail. Furthermore, the integration of the SM family with other promising techniques, applications to emerging communication systems, and extensions to new signal domains are also extensively studied.},
	urldate = {2020-03-16},
	journal = {arXiv:1907.02941 [cs, math]},
	author = {Wen, Miaowen and Zheng, Beixiong and Kim, Kyeong Jin and Di Renzo, Marco and Tsiftsis, Theodoros A. and Chen, Kwang-Cheng and Al-Dhahir, Naofal},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.02941},
	keywords = {Computer Science - Information Theory},
	annote = {Comment: submitted to IEEE Journal on Selected Areas in Communications},
	file = {arXiv Fulltext PDF:/Users/rubenrosales/Zotero/storage/Z2YU5HQU/Wen et al. - 2019 - A Survey on Spatial Modulation in Emerging Wireles.pdf:application/pdf;arXiv.org Snapshot:/Users/rubenrosales/Zotero/storage/5KX58R89/1907.html:text/html}
}

@article{graps_introduction_1995,
	title = {An introduction to wavelets},
	volume = {2},
	issn = {1558-190X},
	doi = {10.1109/99.388960},
	abstract = {Wavelets were developed independently by mathematicians, quantum physicists, electrical engineers and geologists, but collaborations among these fields during the last decade have led to new and varied applications. What are wavelets, and why might they be useful to you? The fundamental idea behind wavelets is to analyze according to scale. Indeed, some researchers feel that using wavelets means adopting a whole new mind-set or perspective in processing data. Wavelets are functions that satisfy certain mathematical requirements and are used in representing data or other functions. Most of the basic wavelet theory has now been done. The mathematics have been worked out in excruciating detail, and wavelet theory is now in the refinement stage. This involves generalizing and extending wavelets, such as in extending wavelet packet techniques. The future of wavelets lies in the as-yet uncharted territory of applications. Wavelet techniques have not been thoroughly worked out in such applications as practical data analysis, where, for example, discretely sampled time-series data might need to be analyzed. Such applications offer exciting avenues for exploration.{\textless}{\textgreater}},
	number = {2},
	journal = {IEEE Computational Science and Engineering},
	author = {Graps, A.},
	year = {1995},
	note = {Conference Name: IEEE Computational Science and Engineering},
	keywords = {applications, Collaboration, data analysis, data represention, discretely sampled time-series data, Fourier series, Geology, Image coding, mathematical requirements, Mathematics, packet techniques, Performance analysis, Prototypes, reviews, scale-based analysis, Signal analysis, signal processing, Signal resolution, Wavelet analysis, wavelet transforms, wavelets},
	pages = {50--61},
	file = {IEEE Xplore Abstract Record:/Users/rubenrosales/Zotero/storage/2C297URX/388960.html:text/html}
}

@book{misiti_wavelets_2013,
	title = {Wavelets and their {Applications}},
	isbn = {978-1-118-61359-7},
	abstract = {The last 15 years have seen an explosion of interest in wavelets with applications in fields such as image compression, turbulence, human vision, radar and earthquake prediction. Wavelets represent an area that combines signal in image processing, mathematics, physics and electrical engineering. As such, this title is intended for the wide audience that is interested in mastering the basic techniques in this subject area, such as decomposition and compression.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Misiti, Michel and Misiti, Yves and Oppenheim, Georges and Poggi, Jean-Michel},
	month = mar,
	year = {2013},
	note = {Google-Books-ID: EeMYyvA5PDoC},
	keywords = {Technology \& Engineering / Electrical, Technology \& Engineering / Signals \& Signal Processing}
}

@article{allen_unified_1977,
	title = {A unified approach to short-time {Fourier} analysis and synthesis},
	volume = {65},
	issn = {1558-2256},
	doi = {10.1109/PROC.1977.10770},
	abstract = {Two distinct methods for synthesizing a signal from its short-time Fourier transform have previously been proposed. We call these methods the filter-bank summation (FBS) method and the overlap add (OLA) method. Each of these synthesis techniques has unique advantages and disadvantages in various applications due to the way in which the signal is reconstructed. In this paper we unify the ideas behind the two synthesis techniques and discuss the similarities and differences between these methods. In particular, we explicitly show the effects of modifications made to the short-time transform (both fixed and time-varying modifications are considered) on the resulting signal and discuss applications where each of the techniques would be most useful The interesting case of nonlinear modifications (possibly signal dependent) to the short-time Fourier transform is also discussed. Finally it is shown that a formal duality exists between the two synthesis methods based on the properties of the window used for obtaining the short-time Fourier transform.},
	number = {11},
	journal = {Proceedings of the IEEE},
	author = {Allen, J.B. and Rabiner, L.R.},
	month = nov,
	year = {1977},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Band pass filters, Equations, Filter bank, Filtering, Fourier transforms, Frequency, Signal analysis, Signal synthesis, Speech analysis, Speech synthesis},
	pages = {1558--1564},
	file = {IEEE Xplore Abstract Record:/Users/rubenrosales/Zotero/storage/SKYBZME9/1455039.html:text/html}
}

@inproceedings{gregory_shape_1985,
	title = {Shape {Preserving} {Spline} {Interpolation}},
	url = {https://ntrs.nasa.gov/search.jsp?R=19850020252},
	abstract = {A rational spline solution to the problem of shape preserving interpolation is discussed. The rational spline is represented in terms of first derivative values at the knots and provides an alternative to the spline-under-tension. The idea of making the shape control parameters dependent on the first derivative unknowns is then explored. The monotonic or convex shape of the interpolation data can then be preserved automatically through the solution of the resulting non-linear consistency equations of the spline.},
	urldate = {2020-03-17},
	author = {Gregory, J. A.},
	month = jun,
	year = {1985},
	keywords = {curves, interpolation, nonlinear equations, polynomials, shapes, spline functions},
	annote = {Document ID: 19850020252; Accession Number: 85N28564; Subject Category: NUMERICAL ANALYSIS; Publisher Information: United States; Financial Sponsor: NASA; United States; Organization Source: Brunel Univ.; Uxbridge, United Kingdom; Description: 7p; In English; Imprint And Other Notes: In NASA.  Langley Research Center  Computational Geometry and Computer-Aided Design  p 1-8},
	annote = {Publication Information: SEE  parent document record,  "NASA.  Langley Research Center  Computational Geometry and Computer-Aided Design"; p. p 1-8},
	file = {NASA NTRS Full Text PDF:/Users/rubenrosales/Zotero/storage/N6HASZJT/Gregory - 1985 - Shape Preserving Spline Interpolation.pdf:application/pdf;Snapshot:/Users/rubenrosales/Zotero/storage/BRYI9HEI/search.html:text/html}
}