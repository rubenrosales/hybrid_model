
@article{tang_digital_2018,
	title = {Digital {Signal} {Modulation} {Classification} {With} {Data} {Augmentation} {Using} {Generative} {Adversarial} {Nets} in {Cognitive} {Radio} {Networks}},
	volume = {6},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2018.2815741},
	abstract = {Automated modulation classification plays a very important part in cognitive radio networks. Deep learning is also a powerful tool that we could not overlook its potential in addressing signal modulation recognition problem. In our last work, we propose a new data conversion algorithm in order to gain a better classification accuracy of communication signal modulation, but we still believe that the convolution neural network (CNN) can work better. However, its application to signal modulation recognition is often hampered by insufficient data and overfitting. Here, we propose a smart approach to programmatic data augmentation method by using the auxiliary classifier generative adversarial networks (ACGANs). The famous CNN model, AlexNet, has been utilized to be the classifier and ACGAN to be the generator, which will enlarge our data set. In order to alleviate the common issues in the traditional generative adversarial nets training, such as discriminator overfitting, generator disconverge, and mode collapse, we apply several training tricks in our training. With the result on original data set as our baseline, we will evaluate our result on enlarged data set to validate the ACGAN’s performance. The result shows that we can gain 0.1 6\% increase in the classification accuracy in the ACGAN-based data set.},
	journal = {IEEE Access},
	author = {Tang, Bin and Tu, Ya and Zhang, Zhaoyue and Lin, Yun},
	year = {2018},
	keywords = {classification algorithms, Cognitive radio, Constellation diagram, convolutional networks, deep learning, Gallium nitride, generative adversarial net, Image color analysis, modulation recognition, pattern recognition, Phase shift keying, Signal to noise ratio, Training},
	pages = {15713--15722},
	file = {IEEE Xplore Abstract Record:/Users/rubenrosales/Zotero/storage/MFQDCCID/Tang et al. - 2018 - Digital Signal Modulation Classification With Data.html:text/html;IEEE Xplore Full Text PDF:/Users/rubenrosales/Zotero/storage/W9NG2XU8/Tang et al. - 2018 - Digital Signal Modulation Classification With Data.pdf:application/pdf}
}

@misc{noauthor_fig_nodate,
	title = {Fig (3-1): {Different} {Wavelet} families {The} first letters has a relation...},
	shorttitle = {Fig (3-1)},
	url = {https://www.researchgate.net/figure/Fig-3-1-Different-Wavelet-families-The-first-letters-has-a-relation-to-the-wavelet_fig2_323005213},
	abstract = {Download scientific diagram {\textbar} Different Wavelet families The first letters has a relation to the wavelet transform is Haar wavelet. It was presented by the mathematician Alfrd Haar in 1909. However, the idea of the wavelet did not present at that time. Until 1981, the model of wavelet was proposed by Jean Morlet. Later, Morlet and Alex Grossman invented the term wavelet in 1984. Before 1985, Haar wavelet was just orthogonal wavelet. A lot of studies although that there was no orthogonal wavelet excepted Haar wavelet. Likely, mathematician called Yves Meyer presented the 2nd orthogonal wavelet called Meyer wavelet in 1985. More than those scholars joined this field in the 1st international conference was held in France in 1987. In 1988, Stephane Mallat and Meyer presented the notation of multi resolution. In the same year, Daubechies found a systematical method to design the orthogonal  from publication: Time-Frequency analysis of Different types of signals {\textbar} Cardiovascular disorders (CVD’s) or Heart disease, which is called coronary artery disease, is a broad term that can refer to a human heart condition. CVD’s are the first cause of death internationally. Taking in consideration that heart auscultation still the primary tool... {\textbar} Heart Sounds, Time-Frequency Analysis and Heart Diseases {\textbar} ResearchGate, the professional network for scientists.},
	language = {en},
	urldate = {2020-03-13},
	journal = {ResearchGate},
	note = {Library Catalog: www.researchgate.net},
	file = {Snapshot:/Users/rubenrosales/Zotero/storage/FC5ZBWSF/Fig-3-1-Different-Wavelet-families-The-first-letters-has-a-relation-to-the-wavelet_fig2_3230052.html:text/html}
}

@article{mesleh_spatial_2008,
	title = {Spatial {Modulation}},
	volume = {57},
	issn = {1939-9359},
	doi = {10.1109/TVT.2007.912136},
	abstract = {Spatial modulation (SM) is a recently developed transmission technique that uses multiple antennas. The basic idea is to map a block of information bits to two information carrying units: 1) a symbol that was chosen from a constellation diagram and 2) a unique transmit antenna number that was chosen from a set of transmit antennas. The use of the transmit antenna number as an information-bearing unit increases the overall spectral efficiency by the base-two logarithm of the number of transmit antennas. At the receiver, a maximum receive ratio combining algorithm is used to retrieve the transmitted block of information bits. Here, we apply SM to orthogonal frequency division multiplexing (OFDM) transmission. We develop an analytical approach for symbol error ratio (SER) analysis of the SM algorithm in independent identically distributed (i.i.d.) Rayleigh channels. The analytical and simulation results closely match. The performance and the receiver complexity of the SM-OFDM technique are compared to those of the vertical Bell Labs layered space-time (V-BLAST-OFDM) and Alamouti-OFDM algorithms. V-BLAST uses minimum mean square error (MMSE) detection with ordered successive interference cancellation. The combined effect of spatial correlation, mutual antenna coupling, and Rician fading on both coded and uncoded systems are presented. It is shown that, for the same spectral efficiency, SM results in a reduction of around 90\% in receiver complexity as compared to V-BLAST and nearly the same receiver complexity as Alamouti. In addition, we show that SM achieves better performance in all studied channel conditions, as compared with other techniques. It is also shown to efficiently work for any configuration of transmit and receive antennas, even for the case of fewer receive antennas than transmit antennas.},
	number = {4},
	journal = {IEEE Transactions on Vehicular Technology},
	author = {Mesleh, Raed Y. and Haas, Harald and Sinanovic, Sinan and Ahn, Chang Wook and Yun, Sangboh},
	month = jul,
	year = {2008},
	note = {Conference Name: IEEE Transactions on Vehicular Technology},
	keywords = {Algorithm design and analysis, Analytical models, Constellation diagram, Error analysis, ICI, information bearing unit, information bits, information carrying unit, Information retrieval, Interchannel interference (ICI), interference cancellation, maximum receive ratio combining algorithm, MIMO, MMSE, modulation, MRRC, multiple antennas, multiple-input–multiple-output (MIMO), Mutual Antenna Coupling, OFDM, orthogonal frequency division multiplexing (OFDM), orthogonal frequency division multiplexing transmission, Rayleigh channels, receive antenna, receiver complexity, Receiver Complexity, receivers, receiving antennas, Receiving antennas, Rician Fading, Samarium, space–time coding (STC) coded modulation, Spatial Correlation, spatial modulation, Spatial Modulation, spatial modulation (SM), spectral efficiency, STBC, symbol error ratio analysis, transmission technique, transmit antenna number, transmitting antennas, Transmitting antennas, V-BLAST, vertical Bell Labs layered space–time (V-BLAST)},
	pages = {2228--2241},
	file = {IEEE Xplore Abstract Record:/Users/rubenrosales/Zotero/storage/ZU2BQLHQ/4382913.html:text/html}
}

@article{wang_multilevel_2018,
	title = {Multilevel {Wavelet} {Decomposition} {Network} for {Interpretable} {Time} {Series} {Analysis}},
	url = {http://arxiv.org/abs/1806.08946},
	abstract = {Recent years have witnessed the unprecedented rising of time series from almost all kindes of academic and industrial fields. Various types of deep neural network models have been introduced to time series analysis, but the important frequency information is yet lack of effective modeling. In light of this, in this paper we propose a wavelet-based neural network structure called multilevel Wavelet Decomposition Network (mWDN) for building frequency-aware deep learning models for time series analysis. mWDN preserves the advantage of multilevel discrete wavelet decomposition in frequency learning while enables the fine-tuning of all parameters under a deep neural network framework. Based on mWDN, we further propose two deep learning models called Residual Classification Flow (RCF) and multi-frequecy Long Short-Term Memory (mLSTM) for time series classification and forecasting, respectively. The two models take all or partial mWDN decomposed sub-series in different frequencies as input, and resort to the back propagation algorithm to learn all the parameters globally, which enables seamless embedding of wavelet-based frequency analysis into deep learning frameworks. Extensive experiments on 40 UCR datasets and a real-world user volume dataset demonstrate the excellent performance of our time series models based on mWDN. In particular, we propose an importance analysis method to mWDN based models, which successfully identifies those time-series elements and mWDN layers that are crucially important to time series analysis. This indeed indicates the interpretability advantage of mWDN, and can be viewed as an indepth exploration to interpretable deep learning.},
	urldate = {2020-03-14},
	journal = {arXiv:1806.08946 [cs, eess, stat]},
	author = {Wang, Jingyuan and Wang, Ze and Li, Jianfeng and Wu, Junjie},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.08946},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/rubenrosales/Zotero/storage/C7TA364N/Wang et al. - 2018 - Multilevel Wavelet Decomposition Network for Inter.pdf:application/pdf;arXiv.org Snapshot:/Users/rubenrosales/Zotero/storage/8YWAXTXA/1806.html:text/html}
}

@article{wang_hybrid_2019,
	title = {Hybrid {Predictive} {Model}: {When} an {Interpretable} {Model} {Collaborates} with a {Black}-box {Model}},
	shorttitle = {Hybrid {Predictive} {Model}},
	url = {http://arxiv.org/abs/1905.04241},
	abstract = {Interpretable machine learning has become a strong competitor for traditional black-box models. However, the possible loss of the predictive performance for gaining interpretability is often inevitable, putting practitioners in a dilemma of choosing between high accuracy (black-box models) and interpretability (interpretable models). In this work, we propose a novel framework for building a Hybrid Predictive Model (HPM) that integrates an interpretable model with any black-box model to combine their strengths. The interpretable model substitutes the black-box model on a subset of data where the black-box is overkill or nearly overkill, gaining transparency at no or low cost of the predictive accuracy. We design a principled objective function that considers predictive accuracy, model interpretability, and model transparency (defined as the percentage of data processed by the interpretable substitute.) Under this framework, we propose two hybrid models, one substituting with association rules and the other with linear models, and we design customized training algorithms for both models. We test the hybrid models on structured data and text data where interpretable models collaborate with various state-of-the-art black-box models. Results show that hybrid models obtain an efficient trade-off between transparency and predictive performance, characterized by our proposed efficient frontiers.},
	urldate = {2020-03-14},
	journal = {arXiv:1905.04241 [cs, stat]},
	author = {Wang, Tong and Lin, Qihang},
	month = may,
	year = {2019},
	note = {arXiv: 1905.04241},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/rubenrosales/Zotero/storage/TT5WKYX4/Wang and Lin - 2019 - Hybrid Predictive Model When an Interpretable Mod.pdf:application/pdf;arXiv.org Snapshot:/Users/rubenrosales/Zotero/storage/IAE9MKM5/1905.html:text/html}
}

@article{oshea_convolutional_2016,
	title = {Convolutional {Radio} {Modulation} {Recognition} {Networks}},
	url = {http://arxiv.org/abs/1602.04105},
	abstract = {We study the adaptation of convolutional neural networks to the complex temporal radio signal domain. We compare the efficacy of radio modulation classification using naively learned features against using expert features which are widely used in the field today and we show significant performance improvements. We show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task especially at low signal to noise ratio.},
	urldate = {2020-03-14},
	journal = {arXiv:1602.04105 [cs]},
	author = {O'Shea, Timothy J. and Corgan, Johnathan and Clancy, T. Charles},
	month = jun,
	year = {2016},
	note = {arXiv: 1602.04105},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/rubenrosales/Zotero/storage/C6E8NQZU/O'Shea et al. - 2016 - Convolutional Radio Modulation Recognition Network.pdf:application/pdf;arXiv.org Snapshot:/Users/rubenrosales/Zotero/storage/LND3XTWF/1602.html:text/html}
}

@book{strang_wavelets_1996,
	title = {Wavelets and {Filter} {Banks}},
	isbn = {978-0-9614088-7-9},
	url = {https://books.google.com/books?id=Z76N_Ab5pp8C},
	publisher = {Wellesley-Cambridge Press},
	author = {Strang, G. and Nguyen, T.},
	year = {1996},
	lccn = {96028791}
}

@article{hill_uncertainty_nodate,
	title = {{THE} {UNCERTAINTY} {PRINCIPLE} {FOR} {FOURIER} {TRANSFORMS} {ON} {THE} {REAL} {LINE}},
	abstract = {This paper will explore the heuristic principle that a function on the line and its Fourier transform cannot both be concentrated on small sets. We begin with the basic properties of the Fourier transform and show that a function and its Fourier transform cannot both have compact support. From there we prove the Fourier inversion theorem and use this to prove the classical uncertainty principle which shows that the spread of a function and its Fourier transform are inversely proportional. Finally, we extend our compactness result from earlier and show that a function and its Fourier transform cannot both be supported on ﬁnite sets.},
	language = {en},
	author = {Hill, Mitch},
	pages = {17},
	file = {Hill - THE UNCERTAINTY PRINCIPLE FOR FOURIER TRANSFORMS O.pdf:/Users/rubenrosales/Zotero/storage/E7I625TQ/Hill - THE UNCERTAINTY PRINCIPLE FOR FOURIER TRANSFORMS O.pdf:application/pdf}
}

@inproceedings{kim_multimodal_2018,
	address = {Galway, Ireland},
	series = {{ASSETS} '18},
	title = {Multimodal {Deep} {Learning} using {Images} and {Text} for {Information} {Graphic} {Classification}},
	isbn = {978-1-4503-5650-3},
	url = {https://doi.org/10.1145/3234695.3236357},
	doi = {10.1145/3234695.3236357},
	abstract = {Information graphics, e.g. line or bar graphs, are often displayed in documents and popular media to support an intended message, but for a growing number of people, they are missing the point. The World Health Organization estimates that the number of people with vision impairment could triple in the next thirty years due to population growth and aging. If a graphic is not described, explained in the text, or missing alt tags and other metadata (as is often the case in popular media), the intended message is lost or not adequately conveyed. In this work, we describe a multimodal deep learning approach that supports the communication of the intended message. The multimodal model uses both the pixel data and text data in a single neural network to classify the information graphic into an intention category that has previously been validated as useful for people who are blind or who are visually impaired. Furthermore, we collect a new dataset of information graphics and present qualitative and quantitative results that show our multimodal model exceeds the performance of any one modality alone, and even surpasses the capabilities of the average human annotator.},
	urldate = {2020-03-13},
	booktitle = {Proceedings of the 20th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Edward and McCoy, Kathleen F.},
	month = oct,
	year = {2018},
	keywords = {assistive technology, classification, deep learning, information graphic, multimodal machine learning},
	pages = {143--148}
}

@article{wang_encoding_nodate,
	title = {Encoding {Time} {Series} as {Images} for {Visual} {Inspection} and {Classification} {Using} {Tiled} {Convolutional} {Neural} {Networks}},
	abstract = {Inspired by recent successes of deep learning in computer vision and speech recognition, we propose a novel framework to encode time series data as different types of images, namely, Gramian Angular Fields (GAF) and Markov Transition Fields (MTF). This enables the use of techniques from computer vision for classiﬁcation. Using a polar coordinate system, GAF images are represented as a Gramian matrix where each element is the trigonometric sum (i.e., superposition of directions) between different time intervals. MTF images represent the ﬁrst order Markov transition probability along one dimension and temporal dependency along the other. We used Tiled Convolutional Neural Networks (tiled CNNs) on 12 standard datasets to learn high-level features from individual GAF, MTF, and GAF-MTF images that resulted from combining GAF and MTF representations into a single image. The classiﬁcation results of our approach are competitive with ﬁve stateof-the-art approaches. An analysis of the features and weights learned via tiled CNNs explains why the approach works.},
	language = {en},
	author = {Wang, Zhiguang and Oates, Tim},
	pages = {7},
	file = {Wang and Oates - Encoding Time Series as Images for Visual Inspecti.pdf:/Users/rubenrosales/Zotero/storage/L5TTWCZT/Wang and Oates - Encoding Time Series as Images for Visual Inspecti.pdf:application/pdf}
}